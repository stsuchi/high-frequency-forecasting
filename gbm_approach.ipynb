{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import math\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section contains the functions of data loading and feature engineering\n",
    "\n",
    "\n",
    "# load the data and aggragate it on 15 minute interval\n",
    "def load_data(myfile='../data/logins2.json'):\n",
    "    df = pd.read_json(myfile)\n",
    "    \n",
    "    # create a pandas Series with timestamp as index\n",
    "    ts_series = pd.Series(1,index=df.login_time)\n",
    "    \n",
    "    # aggregate the count on 15 minute interval\n",
    "    data = ts_series.resample('15T').sum()\n",
    "    data = pd.DataFrame({'login_time':data.index,'count':data.values})\n",
    "    \n",
    "    return data\n",
    "\n",
    "# create all the features\n",
    "\n",
    "def create_features(data):\n",
    "    data['day_category'] = data.login_time.apply(lambda x: str(x)[-8:-3])\n",
    "    data['day_numeric'] = data.day_category.apply(lambda x: create_time_numeric(x))\n",
    "    data['day_cos'] = data.day_numeric.apply(lambda x: math.cos(2*math.pi*x))\n",
    "    data['day_sin'] = data.day_numeric.apply(lambda x: math.sin(2*math.pi*x))\n",
    "    data['day_of_week'] = data.login_time.apply(lambda x: x.weekday())\n",
    "    data['week_numeric'] = data.apply(lambda row: (row['day_of_week'] + row['day_numeric'])/7, axis=1)\n",
    "    data['week_cos'] = data.week_numeric.apply(lambda x: math.cos(2*math.pi*x))\n",
    "    data['week_sin'] = data.week_numeric.apply(lambda x: math.sin(2*math.pi*x))\n",
    "    data['weekend'] = data.day_of_week.apply(lambda x: 1 if x >= 5 else 0)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# After all the features are created in the dataframe\n",
    "# this function extracts and presents them as a 2d list\n",
    "# In the case of preparing the data for future predictions,\n",
    "# y is returned as None as it is not known at the time of \n",
    "# prediction\n",
    "def extract_features(data):\n",
    "    # return arrays\n",
    "    X = data[['day_numeric','day_cos','day_sin','week_numeric','week_cos','week_sin','weekend']].values\n",
    "    if 'count' in data.columns:\n",
    "        y = data['count'].values\n",
    "    else:\n",
    "        y = None\n",
    "    return X, y\n",
    "    \n",
    "# helper function for create_time_numeric\n",
    "def create_numeric_minute(minute_str):\n",
    "    if minute_str == '00':\n",
    "        return 0.25*0 + 0.25/2\n",
    "    elif minute_str == '15':\n",
    "        return 0.25*1 + 0.25/2\n",
    "    elif minute_str == '30':\n",
    "        return 0.25*2 + 0.25/2\n",
    "    elif minute_str == '45':\n",
    "        return 0.25*3 + 0.25/2\n",
    "\n",
    "# helper function for create_features\n",
    "def create_time_numeric(time_category):\n",
    "    h,m = time_category.split(':')\n",
    "    h_num = float(h)\n",
    "    m_num = create_numeric_minute(m)\n",
    "    \n",
    "    time_numeric = (h_num + m_num)/24\n",
    "    \n",
    "    return time_numeric\n",
    "\n",
    "# combine functions in this cell into one\n",
    "def load_and_preprocess():\n",
    "    data = load_data()\n",
    "    data = create_features(data)\n",
    "    X,y = extract_features(data)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00520833  0.99946459  0.03271908  0.57217262 -0.89893063 -0.438091\n",
      "   0.        ]\n",
      " [ 0.015625    0.99518473  0.09801714  0.57366071 -0.89479525 -0.44647671\n",
      "   0.        ]]\n",
      "[3 3]\n"
     ]
    }
   ],
   "source": [
    "# show what we get with these functions\n",
    "\n",
    "X,y = load_and_preprocess()\n",
    "print(X[:2])\n",
    "print(y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up sliding window cross validation and list the values of hyperparameters\n",
    "\n",
    "# sliding window CV.\n",
    "# The list contains of tuples of indices corressponding to specific login time points\n",
    "# 1st tuple: (Jan.1 to Mar. 27 2:45pm) as training and (Mar. 27 3pm to Mar 28 2:45pm) as test\n",
    "# 2nd tuple: (Mar.27 3pm to Jun. 26 2:45pm) as training and (Jun. 26 3pm to Jun. 27 2:45pm) as test\n",
    "# 3rd tuple: (Jun. 26 3pm to Aug. 21 2:45pm) as training and (Aug. 21 3pm to Aug. 22 2:45pm) as test\n",
    "\n",
    "cv=[(list(range(0,8220)),list(range(8220,8316))), (list(range(8220,16956)),list(range(16956,17052))),\\\n",
    "   (list(range(16956,22332)),list(range(22332,22428)))]\n",
    "\n",
    "# list of hyperparameters to tune.\n",
    "grid_params = [{'n_estimators':[300,400,500],'max_depth':[4,5,6],'min_samples_split':[2],\\\n",
    "              'learning_rate':[0.01,0.05,0.1],'loss':['ls']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to run grid search and ts cv\n",
    "# for gradient boosting\n",
    "\n",
    "\n",
    "# use RMSE as the loss function \n",
    "# Define it by myself\n",
    "# the purpose is just to use square root\n",
    "# as sklearn uses MSE.\n",
    "# The same result can be acheived through 'loss':ls\n",
    "# in GradientBoostingRegressor module\n",
    "def RMSE(y_true,y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse**(1/2)\n",
    "    #print('RMSE: %2.3f' % rmse)\n",
    "    return rmse\n",
    "\n",
    "# make it useable for sklearn module\n",
    "my_scorer = make_scorer(RMSE, greater_is_better=True)\n",
    "\n",
    "# run cv with time series data (split is custom and time sequence is maintained)\n",
    "def run_gbm_timeseries_cv(cv,grid_params,X,y):\n",
    "    gbm_cv = GridSearchCV(ensemble.GradientBoostingRegressor(),grid_params,cv=cv,scoring=my_scorer)\n",
    "    gbm_cv.fit(X,y)\n",
    "    print('Parameters of the best model: ', gbm_cv.best_params_)\n",
    "    return gbm_cv\n",
    "\n",
    "# after the cv, fit the best model and get training RMSE\n",
    "def fit_best_gbm(gbm_cv,X,y):\n",
    "    gbm_best = ensemble.GradientBoostingRegressor(**gbm_cv.best_params_)\n",
    "    gbm_best.fit(X,y)\n",
    "    RMSE(y,gbm_best.predict(X))\n",
    "    print('RMSE of the entire data: ', RMSE(y,gbm_best.predict(X)))\n",
    "    return gbm_best\n",
    "\n",
    "# To predict the future, all the features need to be created based on time.\n",
    "# Since the features are only time-based, we can produce without any external reference.\n",
    "# This approach is very similar to simulation\n",
    "def create_data_for_prediction(h=4): \n",
    "    data_future = pd.DataFrame({'login_time':[datetime(2010,8,28,15,0,0) + timedelta(minutes=15*i) for i in range(h)]})\n",
    "    data_future = create_features(data_future)\n",
    "    X_future,y_future = extract_features(data_future)\n",
    "    return X_future,y_future\n",
    "\n",
    "# Put all the gbm part of the functions into one\n",
    "def fit_gbm_model(cv,grid_params):\n",
    "    X,y = load_and_preprocess()\n",
    "    gbm_cv = run_gbm_timeseries_cv(cv,grid_params,X,y)\n",
    "    gbm_best = fit_best_gbm(gbm_cv,X[:22332],y[:22332]) # use the most recent 2 month, just to be on par with Fourier ARIMA prediction\n",
    "    X_future,y_future = create_data_for_prediction()\n",
    "    pred = gbm_best.predict(X_future)\n",
    "    print(\"predictions for the next one hour from 3pm Aug. 28: \", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best model:  {'learning_rate': 0.1, 'loss': 'ls', 'max_depth': 6, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "RMSE of the entire data:  2.119209828836946\n",
      "predictions for the next one hour from 3pm Aug. 28:  [4.79953012 5.51202081 4.90260041 4.67850591]\n"
     ]
    }
   ],
   "source": [
    "fit_gbm_model(cv,grid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
